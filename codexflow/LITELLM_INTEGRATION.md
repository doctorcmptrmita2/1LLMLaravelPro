# LiteLLM Proxy Entegrasyonu

## ğŸ”— LiteLLM Proxy ile Laravel Dashboard Entegrasyonu

LiteLLM proxy'nizden (`https://proxyapison-litellmproxyv1.lc58dd.easypanel.host/`) Laravel dashboard'a log gÃ¶ndermek iÃ§in webhook yapÄ±landÄ±rmasÄ±.

## ğŸ“‹ AdÄ±m 1: Environment Variables

Laravel dashboard `.env` dosyanÄ±za ekleyin:

```env
LITELLM_WEBHOOK_KEY=your_secure_webhook_key_here
LITELLM_PROXY_URL=https://proxyapison-litellmproxyv1.lc58dd.easypanel.host
```

**Ã–NEMLÄ°:** `LITELLM_WEBHOOK_KEY` deÄŸerini gÃ¼Ã§lÃ¼ bir key ile deÄŸiÅŸtirin:
```bash
php artisan tinker
echo bin2hex(random_bytes(32));
```

## ğŸ“‹ AdÄ±m 2: LiteLLM Proxy Webhook YapÄ±landÄ±rmasÄ±

LiteLLM proxy'nizin yapÄ±landÄ±rma dosyasÄ±na (`config.yaml` veya environment variables) webhook ekleyin:

### YÃ¶ntem 1: Environment Variables

```env
WEBHOOK_URL=https://dashboard.codexflow.dev/api/webhook/litellm
WEBHOOK_HEADERS={"X-API-Key": "your_secure_webhook_key_here"}
WEBHOOK_EVENTS=["llm.completion", "llm.streaming", "llm.error"]
```

### YÃ¶ntem 2: config.yaml

```yaml
general_settings:
  webhook_url: "https://dashboard.codexflow.dev/api/webhook/litellm"
  webhook_headers:
    X-API-Key: "your_secure_webhook_key_here"
  webhook_events:
    - "llm.completion"
    - "llm.streaming"
    - "llm.error"
```

## ğŸ“‹ AdÄ±m 3: User API Key Mapping

LiteLLM proxy'de her kullanÄ±cÄ±nÄ±n bir API key'i var. Laravel dashboard'da bu API key'i user ile eÅŸleÅŸtirmek iÃ§in:

### User OluÅŸtururken API Key Kaydet

```php
$user = User::create([
    'name' => 'Test User',
    'email' => 'test@example.com',
    'password' => bcrypt('password'),
    'api_key' => 'cf_' . bin2hex(random_bytes(32)), // LiteLLM'de kullanÄ±lacak key
    'plan' => 'starter',
    'status' => 'active',
]);
```

### LiteLLM Proxy'de User API Key TanÄ±mla

LiteLLM proxy'nizin yapÄ±landÄ±rmasÄ±nda:

```yaml
model_list:
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      api_key: os.environ/OPENAI_API_KEY

# User API keys
user_config:
  - user_id: "cf_abc123..." # Laravel dashboard'daki api_key
    max_budget: 100.0
    allowed_model_region: ["us-east-1"]
```

## ğŸ”„ Webhook AkÄ±ÅŸÄ±

```
1. Client â†’ LiteLLM Proxy (API Ã§aÄŸrÄ±sÄ±)
2. LiteLLM Proxy â†’ AI Provider (OpenAI, Anthropic, vb.)
3. AI Provider â†’ LiteLLM Proxy (Response)
4. LiteLLM Proxy â†’ Laravel Dashboard (Webhook POST)
5. Laravel Dashboard â†’ Database (Log kaydÄ±)
```

## ğŸ“Š Webhook Payload FormatÄ±

LiteLLM webhook'u ÅŸu formatta veri gÃ¶nderir:

```json
{
  "user_id": "cf_abc123...",
  "model": "gpt-4",
  "messages": [...],
  "response": {
    "model": "gpt-4",
    "usage": {
      "prompt_tokens": 100,
      "completion_tokens": 50,
      "total_tokens": 150
    },
    "cost": 0.0015,
    "response_time": 1.25
  },
  "status": "success"
}
```

Laravel dashboard bu veriyi otomatik olarak parse eder ve `api_logs` tablosuna kaydeder.

## ğŸ§ª Test

### 1. Webhook Endpoint'ini Test Et

```bash
curl -X POST https://dashboard.codexflow.dev/api/webhook/litellm \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_secure_webhook_key_here" \
  -d '{
    "user_id": "cf_abc123...",
    "model": "gpt-4",
    "usage": {
      "prompt_tokens": 100,
      "completion_tokens": 50
    },
    "cost": 0.0015,
    "response_time": 1.25,
    "status": "success"
  }'
```

### 2. LiteLLM Proxy'den Test Ä°steÄŸi

```bash
curl -X POST https://proxyapison-litellmproxyv1.lc58dd.easypanel.host/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer cf_abc123..." \
  -d '{
    "model": "gpt-4",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

Bu istekten sonra LiteLLM otomatik olarak webhook gÃ¶nderecek.

## ğŸ” GÃ¼venlik

1. **Webhook Key:** Mutlaka gÃ¼Ã§lÃ¼ bir key kullanÄ±n
2. **HTTPS:** Production'da mutlaka HTTPS kullanÄ±n
3. **Rate Limiting:** Webhook endpoint'ine rate limiting ekleyin (opsiyonel)
4. **IP Whitelist:** Sadece LiteLLM proxy IP'sinden gelen isteklere izin verin (opsiyonel)

## ğŸ“ˆ Dashboard'da GÃ¶rÃ¼ntÃ¼leme

Webhook'tan gelen loglar otomatik olarak:
- Dashboard'da gÃ¶rÃ¼ntÃ¼lenir
- Analytics'te hesaplanÄ±r
- Rate limit'lere eklenir
- Export edilebilir

## ğŸ› Troubleshooting

### Webhook Ã‡alÄ±ÅŸmÄ±yor

1. **Logs kontrol edin:**
```bash
docker-compose logs -f app
# veya
tail -f storage/logs/laravel.log
```

2. **Webhook key kontrol:**
- Laravel `.env` dosyasÄ±nda `LITELLM_WEBHOOK_KEY`
- LiteLLM proxy'de `WEBHOOK_HEADERS` iÃ§inde aynÄ± key

3. **User bulunamÄ±yor:**
- User'Ä±n `api_key` deÄŸerinin LiteLLM'deki `user_id` ile eÅŸleÅŸtiÄŸinden emin olun

### User Mapping HatasÄ±

EÄŸer `user_id` ile user bulunamazsa, webhook'ta `metadata` iÃ§inde `laravel_user_id` gÃ¶nderebilirsiniz:

```json
{
  "user_id": "cf_abc123...",
  "metadata": {
    "laravel_user_id": 1
  },
  ...
}
```

## ğŸ“ Ã–rnek LiteLLM Config

```yaml
# LiteLLM Proxy Config
model_list:
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      api_key: os.environ/OPENAI_API_KEY

general_settings:
  webhook_url: "https://dashboard.codexflow.dev/api/webhook/litellm"
  webhook_headers:
    X-API-Key: "your_secure_webhook_key_here"
  webhook_events:
    - "llm.completion"
    - "llm.error"

user_config:
  - user_id: "cf_abc123..."
    max_budget: 100.0
    allowed_models: ["gpt-4", "gpt-3.5-turbo"]
```

---

**Entegrasyon tamamlandÄ±! ğŸš€**

LiteLLM proxy'nizden gelen tÃ¼m API Ã§aÄŸrÄ±larÄ± otomatik olarak Laravel dashboard'a kaydedilecek.

